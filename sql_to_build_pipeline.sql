-- Create the table that we will use as our source of truth to train on
create or replace TABLE INSURANCE.ML_PIPE.SOURCE_OF_TRUTH (
	AGE NUMBER(38,0),
	GENDER VARCHAR(16777216),
	BMI FLOAT,
	CHARGES FLOAT,
	CHILDREN NUMBER(38,0),
	SMOKER VARCHAR(16777216),
	REGION VARCHAR(16777216),
	MEDICAL_HISTORY VARCHAR(16777216),
	FAMILY_MEDICAL_HISTORY VARCHAR(16777216),
	EXERCISE_FREQUENCY VARCHAR(16777216),
	OCCUPATION VARCHAR(16777216),
	COVERAGE_LEVEL VARCHAR(16777216)
);

-- Insert only 10,000 rows. That way, we can save the rest for inference. As if they were new records
-- coming in from a streaming source, such as a website or forms. 
INSERT INTO INSURANCE.ML_PIPE.SOURCE_OF_TRUTH (
    AGE ,
	GENDER,
	BMI,
	CHARGES ,
	CHILDREN,
	SMOKER,
	REGION,
	MEDICAL_HISTORY ,
	FAMILY_MEDICAL_HISTORY,
	EXERCISE_FREQUENCY ,
	OCCUPATION ,
	COVERAGE_LEVEL
) SELECT AGE ,
	GENDER,
	BMI,
	CHARGES ,
	CHILDREN,
	SMOKER,
	REGION,
	MEDICAL_HISTORY ,
	FAMILY_MEDICAL_HISTORY,
	EXERCISE_FREQUENCY ,
	OCCUPATION ,
	COVERAGE_LEVEL
FROM PUBLIC.INSURANCE_DATASET limit 10000; -- PUBLIC.INSURANCE_DATASET is a table that I loaded with the insurance dataset csv from kaggle. 

-- Create table that will hold the testing observations (potentially could be streamed in)
create or replace TABLE INSURANCE.ML_PIPE.INCOMING_DATA_SOURCE (
	AGE NUMBER(38,0),
	GENDER VARCHAR(16777216),
	BMI FLOAT,
	CHARGES FLOAT,
	CHILDREN NUMBER(38,0),
	SMOKER VARCHAR(16777216),
	REGION VARCHAR(16777216),
	MEDICAL_HISTORY VARCHAR(16777216),
	FAMILY_MEDICAL_HISTORY VARCHAR(16777216),
	EXERCISE_FREQUENCY VARCHAR(16777216),
	OCCUPATION VARCHAR(16777216),
	COVERAGE_LEVEL VARCHAR(16777216)
);
-- I loaded this table through Snowpark such that it has the remaining 990k 
-- rows of the original insurance dataset. 

-- Create a stage to hold the SPROCs
CREATE STAGE ML_PIPE_STAGE;


-- Create the landing table (where streamed-in records could land)
create or replace TABLE INSURANCE.ML_PIPE.LANDING_TABLE (
	AGE NUMBER(38,0),
	GENDER VARCHAR(16777216),
	BMI FLOAT,
	CHARGES FLOAT,
	CHILDREN NUMBER(38,0),
	SMOKER VARCHAR(16777216),
	REGION VARCHAR(16777216),
	MEDICAL_HISTORY VARCHAR(16777216),
	FAMILY_MEDICAL_HISTORY VARCHAR(16777216),
	EXERCISE_FREQUENCY VARCHAR(16777216),
	OCCUPATION VARCHAR(16777216),
	COVERAGE_LEVEL VARCHAR(16777216)
);

-- Create the stream on the landing table
CREATE OR REPLACE STREAM STREAM_ON_LANDING ON TABLE LANDING_TABLE;

-- Insert records into the landing table to simulate streamed data
INSERT INTO LANDING_TABLE(
    AGE ,
	GENDER,
	BMI,
	CHARGES ,
	CHILDREN,
	SMOKER,
	REGION,
	MEDICAL_HISTORY ,
	FAMILY_MEDICAL_HISTORY,
	EXERCISE_FREQUENCY ,
	OCCUPATION ,
	COVERAGE_LEVEL
) SELECT 
    AGE,
	GENDER,
	BMI,
	CHARGES ,
	CHILDREN,
	SMOKER,
	REGION,
	MEDICAL_HISTORY ,
	FAMILY_MEDICAL_HISTORY,
	EXERCISE_FREQUENCY ,
	OCCUPATION ,
	COVERAGE_LEVEL
FROM INCOMING_DATA_SOURCE
LIMIT 100; -- Change this number to test prediction speed at different quantities

-- View the inserted records in the stream, along with the added metadata columns
SELECT * FROM STREAM_ON_LANDING;



-- Create a gold table for the records and their predictions to land
CREATE OR REPLACE TABLE INSURANCE_GOLD(
    AGE NUMBER(38,0),
	GENDER VARCHAR(16777216),
	BMI FLOAT,
	CHILDREN NUMBER(38,0),
	SMOKER VARCHAR(16777216),
	REGION VARCHAR(16777216),
	MEDICAL_HISTORY VARCHAR(16777216),
	FAMILY_MEDICAL_HISTORY VARCHAR(16777216),
	EXERCISE_FREQUENCY VARCHAR(16777216),
	OCCUPATION VARCHAR(16777216),
	COVERAGE_LEVEL VARCHAR(16777216),
    METADATA$ROW_ID VARCHAR(16777216),
    METADATA$ISUPDATE BOOLEAN,
    METADATA$ACTION VARCHAR(16777216),
    METADATA_UPDATED_AT DATE,
    CHARGES FLOAT,
    PREDICTED_CHARGES FLOAT
);

-- Call the saved prediction SPROC
CALL PREDICT_WRITE_TO_GOLD();

-- Testing the capacity to update records that already exist in the gold table
update landing_table set coverage_level = 'STANDARD'
where age = 41;


-- Create the tasks that call the training sproc. Sprocs are created in the python files
CREATE or REPLACE TASK TRAIN_SAVE_TASK
  WAREHOUSE = COMPUTE_WH
  SCHEDULE = '11520 MINUTE' -- Executes every 8 days 
  AS
    CALL TRAIN_SAVE_INS_MODEL('SOURCE_OF_TRUTH',FALSE);

-- Create the predict and write task
CREATE or REPLACE TASK PREDICT_WRITE_TASK
  WAREHOUSE = COMPUTE_WH
  SCHEDULE = '1 MINUTE'
  WHEN
    SYSTEM$STREAM_HAS_DATA('STREAM_ON_LANDING')
  AS
    CALL PREDICT_WRITE_TO_GOLD();
